{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "quiet-fashion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "specialized-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occupational-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "#     'model': 'hfl/chinese-macbert-base',\n",
    "    'model': 'nghuyong/ernie-1.0',\n",
    "    'max_len': 512, \n",
    "    'epochs': 5,\n",
    "    'train_bs': 30, \n",
    "    'valid_bs': 30,\n",
    "    'lr': 2e-5, \n",
    "    'num_workers': 0,\n",
    "    'accum_iter': 1, \n",
    "    'weight_decay': 1e-6, \n",
    "    'device': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "organized-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['seed'])\n",
    "\n",
    "torch.cuda.set_device(CFG['device'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generic-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =  pd.read_csv('train.csv')\n",
    "train_new_df =  pd.read_csv('train_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "still-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(-1, inplace=True)\n",
    "train_new_df.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "simplified-defeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 43551/168714 [00:00<00:00, 143989.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source    英国伦敦，20/21赛季英超第20轮，托特纳姆热刺VS利物浦。热刺本赛季18轮联赛是9胜6平...\n",
      "target     北京时间1月29日凌晨4时，英超联赛第20轮迎来一场强强对话，热刺坐镇主场迎战利物浦。  ...\n",
      "labelA                                                 -1.0\n",
      "labelB                                                  0.0\n",
      "type                                                     ss\n",
      "len1                                                    146\n",
      "len2                                                    150\n",
      "Name: 28327, dtype: object\n",
      "source    英国伦敦，20/21赛季英超第20轮，托特纳姆热刺VS利物浦。热刺本赛季18轮联赛是9胜6平...\n",
      "target     北京时间1月29日凌晨4时，英超联赛第20轮迎来一场强强对话，热刺坐镇主场迎战利物浦。  ...\n",
      "labelA                                                  1.0\n",
      "labelB                                                 -1.0\n",
      "type                                                     ss\n",
      "len1                                                    146\n",
      "len2                                                    150\n",
      "Name: 34125, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168714/168714 [00:01<00:00, 143464.45it/s]\n"
     ]
    }
   ],
   "source": [
    "t = '英国伦敦，20/21赛季英超第20轮，托特纳姆热刺VS利物浦。热刺本赛季18轮联赛是9胜6平3负，目前积33分排名联赛第5位。'\n",
    "for i in tqdm(range(len(train_df))):\n",
    "    if t in train_df.loc[i,'source']:\n",
    "        print(train_df.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "thousand-reduction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['英国伦敦，20/21赛季英超第20轮，托特纳姆热刺VS利物浦。热刺本赛季18轮联赛是9胜6平3负，目前积33分排名联赛第5位。利物浦本赛季19轮联赛是9胜7平3负，目前积34分排名联赛第4位。从目前的走势来看，本场比赛从热刺的角度来讲，是非常被动的。最终，本场比赛的比分为托特纳姆热刺1-3利',\n",
       "       ' 北京时间1月29日凌晨4时，英超联赛第20轮迎来一场强强对话，热刺坐镇主场迎战利物浦。  热刺vs利物浦，比赛看点如下： 第一：热刺能否成功复仇？双方首回合，热刺客场1-2被利物浦绝杀，赛后穆里尼奥称最好的球队输了，本轮热刺主场迎战利物浦，借着红军5轮不胜的低迷状态，能否成功复仇？ 第二：利物浦近',\n",
       "       -1.0, 0.0, 'ss', 146, 150], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[28327].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "active-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['ernie_round1_train.npy',\n",
    "'ernie_round2_train.npy',\n",
    "'ernie_round3_train.npy',\n",
    "'maclarge_round1_train.npy',\n",
    "'maclarge_round3_train.npy',\n",
    "'macbase_round1_train.npy',\n",
    "'macbase_round2_train.npy',\n",
    "'macbase_round3_train.npy',\n",
    "]\n",
    "\n",
    "probs = []\n",
    "for file in files:\n",
    "    prob = np.load(file)\n",
    "    probs.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "several-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.mean(probs,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "charged-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['ernie_round1_train_new.npy',\n",
    "'ernie_round2_train_new.npy',\n",
    "'ernie_round3_train_new.npy',\n",
    "'maclarge_round1_train_new.npy',\n",
    "'maclarge_round3_train_new.npy',\n",
    "'macbase_round1_train_new.npy',\n",
    "'macbase_round2_train_new.npy',\n",
    "'macbase_round3_train_new.npy',\n",
    "]\n",
    "\n",
    "probs_new = []\n",
    "for file in files:\n",
    "    prob = np.load(file)\n",
    "    probs_new.append(prob)\n",
    "probs_new = np.mean(probs_new,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "traditional-shannon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((168714, 2), (96777, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape, probs_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ethical-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs = np.concatenate([probs, probs_new],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "retired-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, train_new_df], 0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "written-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['stratify'] = 3*(train_df.labelA+1)+train_df.labelB+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "inclusive-canyon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>labelA</th>\n",
       "      <th>labelB</th>\n",
       "      <th>type</th>\n",
       "      <th>len1</th>\n",
       "      <th>len2</th>\n",
       "      <th>stratify</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>谁能打破科比81分纪录？奥尼尔给出5个候选人，补充利拉德比尔！</td>\n",
       "      <td>NBA现役能入名人堂的球星很多，但是能被立铜像只有2人</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>请扩散！明天，黄金埠这些地方会停电！</td>\n",
       "      <td>生活｜这几个地方注意啦！1月12日有部分线路停电检修</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>居家健身增强免疫！（三）</td>\n",
       "      <td>原来是背影杀手#你愿意和我做朋友吗#户外健身</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>太极拳罗师傅被洋人打伤，叶问霸气复仇？</td>\n",
       "      <td>非常完美：感动！女嘉宾告白赵杰被拒绝，尹康霸气上台挽留！</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>恭喜哈登！篮网因祸得福，29+7超巨大概率复出，3换4交易方案出炉</td>\n",
       "      <td>三英缺席杜兰特，篮网迎战湖人NBA重头大戏！</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265486</th>\n",
       "      <td>96772</td>\n",
       "      <td>北京时间1月9日，CBA第28轮的一场比赛率先开打，北控男篮对阵上海男篮，近期状态不错的上海...</td>\n",
       "      <td>北京时间1月13日，上海神塔董瀚麟打出大爆发一战，面对与周琦、莫泰的双塔对决，他奉献7中7...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ll</td>\n",
       "      <td>788</td>\n",
       "      <td>652</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265487</th>\n",
       "      <td>96773</td>\n",
       "      <td>桌球界金童玉女江宏杰、福原爱爆婚姻亮红灯。（图／翻摄自福原爱脸书） 桌球界金童玉女江宏杰、...</td>\n",
       "      <td>福原爱江宏杰 搜狐娱乐讯据台媒，福原爱与小5岁早稻田学弟约会出游，陷入不伦疑云，与江宏杰4年...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ll</td>\n",
       "      <td>524</td>\n",
       "      <td>1142</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265488</th>\n",
       "      <td>96774</td>\n",
       "      <td>现在的NBA联盟和之前根本不一样了，如今的联盟更加注重的是几个球星在一起联手夺冠，如果你还在...</td>\n",
       "      <td>4月3日·周六10:00 雄鹿（客）VS开拓者（主） 场外因素 字母哥和利拉德，可以说是目前...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ll</td>\n",
       "      <td>567</td>\n",
       "      <td>593</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265489</th>\n",
       "      <td>96775</td>\n",
       "      <td>近年来，智能技术的普及应用给人们的生活带来了便利，但也给部分老年人带来了烦恼和难题。随着中国...</td>\n",
       "      <td>科学技术的发展，在便利了年轻群体的同时，也让没能跟上步伐的老年人群体，逐渐面临“数字鸿沟”。...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ll</td>\n",
       "      <td>1665</td>\n",
       "      <td>701</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265490</th>\n",
       "      <td>96776</td>\n",
       "      <td>据《河北日报》微信公众号消息，1月16日，邯郸市第十五届人民代表大会常务委员会第三十次会议决...</td>\n",
       "      <td>据《新华日报》消息，1月14日上午，中国共产党的优秀党员、江苏省人大常委会原副主任、中共苏州...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ll</td>\n",
       "      <td>1018</td>\n",
       "      <td>1172</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265491 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                             source  \\\n",
       "0           0                    谁能打破科比81分纪录？奥尼尔给出5个候选人，补充利拉德比尔！   \n",
       "1           1                                 请扩散！明天，黄金埠这些地方会停电！   \n",
       "2           2                                       居家健身增强免疫！（三）   \n",
       "3           3                                太极拳罗师傅被洋人打伤，叶问霸气复仇？   \n",
       "4           4                  恭喜哈登！篮网因祸得福，29+7超巨大概率复出，3换4交易方案出炉   \n",
       "...       ...                                                ...   \n",
       "265486  96772  北京时间1月9日，CBA第28轮的一场比赛率先开打，北控男篮对阵上海男篮，近期状态不错的上海...   \n",
       "265487  96773   桌球界金童玉女江宏杰、福原爱爆婚姻亮红灯。（图／翻摄自福原爱脸书） 桌球界金童玉女江宏杰、...   \n",
       "265488  96774  现在的NBA联盟和之前根本不一样了，如今的联盟更加注重的是几个球星在一起联手夺冠，如果你还在...   \n",
       "265489  96775  近年来，智能技术的普及应用给人们的生活带来了便利，但也给部分老年人带来了烦恼和难题。随着中国...   \n",
       "265490  96776  据《河北日报》微信公众号消息，1月16日，邯郸市第十五届人民代表大会常务委员会第三十次会议决...   \n",
       "\n",
       "                                                   target  labelA  labelB  \\\n",
       "0                             NBA现役能入名人堂的球星很多，但是能被立铜像只有2人     0.0    -1.0   \n",
       "1                              生活｜这几个地方注意啦！1月12日有部分线路停电检修     0.0    -1.0   \n",
       "2                                  原来是背影杀手#你愿意和我做朋友吗#户外健身     0.0    -1.0   \n",
       "3                            非常完美：感动！女嘉宾告白赵杰被拒绝，尹康霸气上台挽留！     0.0    -1.0   \n",
       "4                                  三英缺席杜兰特，篮网迎战湖人NBA重头大戏！     1.0    -1.0   \n",
       "...                                                   ...     ...     ...   \n",
       "265486   北京时间1月13日，上海神塔董瀚麟打出大爆发一战，面对与周琦、莫泰的双塔对决，他奉献7中7...    -1.0     0.0   \n",
       "265487  福原爱江宏杰 搜狐娱乐讯据台媒，福原爱与小5岁早稻田学弟约会出游，陷入不伦疑云，与江宏杰4年...    -1.0     1.0   \n",
       "265488  4月3日·周六10:00 雄鹿（客）VS开拓者（主） 场外因素 字母哥和利拉德，可以说是目前...    -1.0     0.0   \n",
       "265489  科学技术的发展，在便利了年轻群体的同时，也让没能跟上步伐的老年人群体，逐渐面临“数字鸿沟”。...    -1.0     0.0   \n",
       "265490  据《新华日报》消息，1月14日上午，中国共产党的优秀党员、江苏省人大常委会原副主任、中共苏州...    -1.0     0.0   \n",
       "\n",
       "       type  len1  len2  stratify  \n",
       "0        ss    31    27       3.0  \n",
       "1        ss    18    26       3.0  \n",
       "2        ss    12    22       3.0  \n",
       "3        ss    19    30       3.0  \n",
       "4        ss    33    22       6.0  \n",
       "...     ...   ...   ...       ...  \n",
       "265486   ll   788   652       1.0  \n",
       "265487   ll   524  1142       2.0  \n",
       "265488   ll   567   593       1.0  \n",
       "265489   ll  1665   701       1.0  \n",
       "265490   ll  1018  1172       1.0  \n",
       "\n",
       "[265491 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "moderate-holocaust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>labelA</th>\n",
       "      <th>labelB</th>\n",
       "      <th>type</th>\n",
       "      <th>len1</th>\n",
       "      <th>len2</th>\n",
       "      <th>stratify</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>379</td>\n",
       "      <td>警惕！7人感染</td>\n",
       "      <td>早知天下事</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>2301</td>\n",
       "      <td>新年快乐</td>\n",
       "      <td>政已阅祝您新年快乐！</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>2616</td>\n",
       "      <td>&gt;&gt;A02</td>\n",
       "      <td>戳图查看详情↑</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>3000</td>\n",
       "      <td>电影里的图片</td>\n",
       "      <td>电影里的图片</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>3035</td>\n",
       "      <td>电影里面的图片</td>\n",
       "      <td>电影里面的图片</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191738</th>\n",
       "      <td>23024</td>\n",
       "      <td>备年货迎新春</td>\n",
       "      <td>备年货迎新春</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192129</th>\n",
       "      <td>23415</td>\n",
       "      <td>惊蛰日，学雷锋</td>\n",
       "      <td>惊蛰日，学雷锋</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192146</th>\n",
       "      <td>23432</td>\n",
       "      <td>兑彩票</td>\n",
       "      <td>兑彩票</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192543</th>\n",
       "      <td>23829</td>\n",
       "      <td>发个库存照片</td>\n",
       "      <td>最后一个库存</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192885</th>\n",
       "      <td>24171</td>\n",
       "      <td>闺蜜旅行</td>\n",
       "      <td>闺蜜旅行</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index   source      target  labelA  labelB type  len1  len2  stratify\n",
       "379       379  警惕！7人感染       早知天下事     0.0    -1.0   ss     7     5       3.0\n",
       "2301     2301     新年快乐  政已阅祝您新年快乐！     1.0    -1.0   ss     4    10       6.0\n",
       "2616     2616    >>A02     戳图查看详情↑     0.0    -1.0   ss     5     7       3.0\n",
       "3000     3000   电影里的图片      电影里的图片     1.0    -1.0   ss     6     6       6.0\n",
       "3035     3035  电影里面的图片     电影里面的图片     1.0    -1.0   ss     7     7       6.0\n",
       "...       ...      ...         ...     ...     ...  ...   ...   ...       ...\n",
       "191738  23024   备年货迎新春      备年货迎新春    -1.0     1.0   ss     6     6       2.0\n",
       "192129  23415  惊蛰日，学雷锋     惊蛰日，学雷锋    -1.0     1.0   ss     7     7       2.0\n",
       "192146  23432      兑彩票         兑彩票    -1.0     1.0   ss     3     3       2.0\n",
       "192543  23829   发个库存照片      最后一个库存    -1.0     0.0   ss     6     8       1.0\n",
       "192885  24171     闺蜜旅行        闺蜜旅行    -1.0     1.0   ss     4     4       2.0\n",
       "\n",
       "[92 rows x 9 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.query('len1+len2 < 15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cheap-cleaners",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMQElEQVR4nO3dcaid913H8fenSTuzpKsZvWRE2wU1Tp0SixfXhnSk2srKrEJUNrRT6SRVh0X8Y04W/WOIHVJ0VuxsXOwqA1kRHFOr4CjSaIzjZv4hK0r9I1UihTvtck1hoN3XP86pyZK0Ofc5N89J8n2/oOQ5v+e59/5OfuG++zzPOfemqpAk9XXdoicgSVosQyBJzRkCSWrOEEhSc4ZAkpozBJLU3OZFT2C9br755tq1a9eipyFJV5UTJ058qaqWLrbvqgvBrl27WFlZWfQ0JOmqkuSF19rnpSFJas4QSFJzhkCSmjMEktScIZCk5mYKQZIdSY5Ot69P8udJjiV54HKMSZLGc8kQJNkOPAlsnQ79ArBSVXuBH0xy42UYkySNZJYzgleA9wBr08f7gaem28eA5csw9jWSHEyykmRldXV1hilLkmZ1yTeUVdUaQJJXh7YCp6bba8COyzB2/hwOA4cBlpeX/U06mtmDDy56BpfP448vega6Vgx5Z/EZYAtwGtg2fbzRY5Kau5YjDldWyIe8augEsG+6vQc4eRnGJEkjGXJG8CTwdJI7ge8A/oHJpZ2NHJMkjWTmM4Kq2j/98wXgHuDvgLur6pWNHtu4pydJupRBP320qv6Ds6/0uSxjkqRx+M5iSWrOEEhSc4ZAkpozBJLUnCGQpOYMgSQ1ZwgkqTlDIEnNGQJJas4QSFJzhkCSmjMEktScIZCk5gyBJDVnCCSpOUMgSc0ZAklqzhBIUnOGQJKaMwSS1JwhkKTmDIEkNWcIJKk5QyBJzRkCSWrOEEhSc4ZAkpozBJLUnCGQpOYMgSQ1ZwgkqTlDIEnNrTsESbYneTrJ0SS/Px07kuRYkkPnHDd4TJI0niFnBO8DPlVVdwI3JvkgsKmq9gI7k+xOcmDo2AY9L0nSjDYP+Jj/BN6W5OuBW4DTwFPTfc8A+4Db5hh7fsCcJEkDDTkj+FtgN/AQ8M/AG4BT031rwA5g6xxjF0hyMMlKkpXV1dUBU5YkvZYhIfgN4Ger6iNMQvDjwJbpvm3Tz3lmjrELVNXhqlququWlpaUBU5YkvZYhIXgj8F1JNgHvAD7K5JIOwB7gJHBijjFJ0oiG3CN4GHgCeCvw98BvA0eT7ATuBW4Hao4xSdKI1n1GUFWfr6q3V9W2qrqnqtaA/cBx4K6qOj3P2EY8KUnS7IacEVygql7i7Kt/5h6TJI3HdxZLUnOGQJKaMwSS1JwhkKTmDIEkNWcIJKk5QyBJzRkCSWrOEEhSc4ZAkpozBJLUnCGQpOYMgSQ1ZwgkqTlDIEnNGQJJas4QSFJzhkCSmjMEktScIZCk5jbkl9dfyx58cNEzuLwef3zRM5C0aJ4RSFJzhkCSmjMEktScIZCk5gyBJDVnCCSpOUMgSc0ZAklqzhBIUnOGQJKaMwSS1JwhkKTmBocgyWNJ7ptuH0lyLMmhc/YPHpMkjWdQCJLcCbylqv4syQFgU1XtBXYm2T3P2AY9L0nSjNYdgiTXA38AnEzyw8B+4Knp7meAfXOOXexrHkyykmRldXV1vVOWJL2OIWcEPwk8B/wm8L3AB4BT031rwA5g6xxjF6iqw1W1XFXLS0tLA6YsSXotQ34xzW3A4ap6McmngL3Alum+bUzicmaOMUnSiIZ84/1X4Jum28vALs5e0tkDnAROzDEmSRrRkDOCI8AfJnkvcD2T6/yfTbITuBe4HSjg6MAxSdKI1n1GUFX/XVU/VlXvrKo7quoFJjE4DtxVVaeram3o2EY8KUnS7Dbkl9dX1UucffXP3GOSpPF4c1aSmjMEktScIZCk5gyBJDVnCCSpOUMgSc0ZAklqzhBIUnOGQJKaMwSS1JwhkKTmDIEkNWcIJKk5QyBJzRkCSWrOEEhSc4ZAkpozBJLUnCGQpOYMgSQ1ZwgkqTlDIEnNGQJJas4QSFJzhkCSmjMEktScIZCk5gyBJDVnCCSpOUMgSc0ZAklqzhBIUnODQ5BkR5J/nG4fSXIsyaFz9g8ekySNZ54zgkeALUkOAJuqai+wM8nuecbmfUKSpPXZPOSDknwf8DLwIrAfeGq66xlgH3DbHGPPD5mTJGmYdZ8RJLkB+DXgQ9OhrcCp6fYasGPOsYt9zYNJVpKsrK6urnfKkqTXMeTS0IeA36uqL08fnwG2TLe3TT/nPGMXqKrDVbVcVctLS0sDpixJei1DQnA38IEkfwN8N3Afk0s6AHuAk8CJOcYkSSNa9z2Cqnrnq9vTGPwQcDTJTuBe4Hag5hiTJI1orvcRVNX+qlpjcsP4OHBXVZ2eZ2ye+UiS1m/Qq4bOV1UvcfbVP3OPSZLG4zuLJak5QyBJzRkCSWrOEEhSc4ZAkpozBJLUnCGQpOYMgSQ1ZwgkqTlDIEnNGQJJas4QSFJzhkCSmjMEktScIZCk5gyBJDVnCCSpOUMgSc0ZAklqzhBIUnOGQJKaMwSS1JwhkKTmDIEkNWcIJKk5QyBJzRkCSWrOEEhSc4ZAkpozBJLUnCGQpOYMgSQ1Zwgkqbl1hyDJTUn+MslfJ/nTJDckOZLkWJJD5xw3eEySNJ4hZwQ/AfxWVd0DvAi8F9hUVXuBnUl2JzkwdGxjnpYkaVab1/sBVfXYOQ+XgPuBj00fPwPsA24Dnho49vz5XzPJQeAgwK233rreKUuSXsfgewRJ7gC2A/8OnJoOrwE7gK1zjF2gqg5X1XJVLS8tLQ2dsiTpIgaFIMmbgd8FHgDOAFumu7ZNP+c8Y5KkEQ25WXwDk8s5v1JVLwAnmFzSAdgDnJxzTJI0onXfIwDeD3wP8OEkHwaeAN6XZCdwL3A7UMDRgWOSpBGt+4ygqj5eVdurav/0vyeB/cBx4K6qOl1Va0PHNuJJSZJmN+SM4AJV9RJnX/0z95gkaTzenJWk5gyBJDVnCCSpOUMgSc0ZAklqzhBIUnOGQJKaMwSS1JwhkKTmDIEkNWcIJKk5QyBJzRkCSWrOEEhSc4ZAkpozBJLUnCGQpOYMgSQ1ZwgkqTlDIEnNGQJJas4QSFJzhkCSmjMEktScIZCk5gyBJDVnCCSpOUMgSc0ZAklqzhBIUnOGQJKaMwSS1JwhkKTmrogQJDmS5FiSQ4ueiyR1s/AQJDkAbKqqvcDOJLsXPSdJ6iRVtdgJJI8Cf1VVTyf5UeDGqnrivGMOAgenD98G/MvI0xzTzcCXFj0JDeLaXd2u9fV7a1UtXWzH5rFnchFbgVPT7TXgW84/oKoOA4fHnNSiJFmpquVFz0Pr59pd3Tqv38IvDQFngC3T7W1cGXOSpDauhG+6J4B90+09wMnFTUWS+rkSLg19BjiaZCdwL3D7YqezcC0ugV2jXLurW9v1W/jNYoAk24F7gGer6sVFz0eSOrkiQiBJWpwr4R5BG0l+JsmN0+3rk1x3zr5NSa6b5ZjxZy6Ybf0WNztpOM8IRpIkwHPA26vqq0l+Hng38D/TQzYDvwz8yaWOqaovjjt7zbp+VfXFJO8G7qiqQ9OPfRT4XFV9dhFz11mzrE3H9bsSbhZ38W3ANwCfT3I9cF9VPXbuAUm+/VLHaGEuuX7neAX43+kZwqPAl6/lbyJXmVnWpt36eUYwkiQfZPLS2AeA+4GvA54B/m16yFuAP7rUMVX1naNNWv9vlvV7dW2SvIvJq9+2AM9X1SdGn7Auapa16bh+nhGM55PAm5m8ae5m4CvAsar6aYAkfzHjMVqMT3KJtUnyHuAh4EbgTUwisS/J/dPP8QbgV6vqc+NOXTOuzcdmOOaaXD9DMJ5vBN4B3ALcDXwB+IEkr/6j+tYZj9FiXHJtqurTwKfP+T/KjwDHgO+vqq8sYM6aWsfatFw/X+Uwkqr6ApNLP5uBPwaOM7m5eDeTH6j3yCzHLGLumm39LvIxXwWOAB8dcaqawSxr02n9DMG4DgBHmVxbvgV4KMlNwLuAN67jGC3GetbmpiSfAP4L2Jrkd5K4fleGWdam1foZgpEkuQH4JeAXgV8HtgMfZ/JKlB8BDs9yzNjz1sQ61+abgfcz+TlanwF+jskPV1xJ8qbRJq2LmWVt2q2frxoaSZKfApaq6pHp48NMvonA5Ift/ROTyw0vX+KYZ6vq4THnrpnX79mqejjJrcC2qnruvM+xtapeHnPe+lqzrE3H9TMEI0qSusRf+CzHaDFcG12rDIEkNec9AklqzhBIUnOGQJKaMwSS1JwhkKTm/g9kKucbZ7t5fwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.type.value_counts().sort_index(ascending=False).plot.bar(color=\"blue\",alpha=0.6)\n",
    "plt.xticks(range(3),['短短','短长','长长'],rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "handmade-agriculture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_width = 0.25\n",
    "x = np.arange(2)\n",
    "y1 = train_df.query('labelA != -1').labelA.value_counts()\n",
    "y2 = train_df.query('labelB != -1').labelB.value_counts()\n",
    "plt.bar(x,y1,bar_width,color=\"blue\",align=\"center\",label=\"A\",alpha=0.6)\n",
    "plt.bar(x+bar_width,y2,bar_width,color=\"red\",align=\"center\",label=\"B\",alpha=0.6)\n",
    "plt.xlabel(\"标签值\")\n",
    "plt.ylabel(\"数量\")\n",
    "plt.xticks(x+bar_width/2,[0,1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "accomplished-mortgage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(count    67162.000000\n",
       " mean        59.734657\n",
       " std         48.766638\n",
       " min          3.000000\n",
       " 25%         24.000000\n",
       " 50%         30.000000\n",
       " 75%        110.000000\n",
       " max        150.000000\n",
       " Name: len1, dtype: float64,\n",
       " count    67162.000000\n",
       " mean        60.190539\n",
       " std         48.455424\n",
       " min          3.000000\n",
       " 25%         24.000000\n",
       " 50%         31.000000\n",
       " 75%        110.000000\n",
       " max        150.000000\n",
       " Name: len2, dtype: float64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.query('type==\\'ss\\'').len1.plot.hist()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "train_df.query('type==\\'ss\\'').len1.describe(),train_df.query('type==\\'ss\\'').len2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "asian-province",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD2CAYAAADBAmBkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAO5UlEQVR4nO3da4wdd3nH8e+vdkyNnaamWZka1bgV7gUIbsQWHNdJ14ioSoEiQoGIO0GySih90RdtEBFVkLhVCIqgKbhKUSgXEakClUuK0qYRBhPAbgUpNCgVcoC0UQ1KvJhWVYGnL85Y3qw3yfz37Jnd4/1+pCPPPHPW8398dva3c3WqCkmS+vqp1R6AJGm6GBySpCYGhySpicEhSWpicEiSmmxc7QFM2oUXXli7du1a7WFI0lQ5duzY96pqZqll53xw7Nq1i6NHj672MCRpqiS556GWeahKktTE4JAkNTE4JElNDA5JUhODQ5LUZCLBkWR7ksPd9HlJPpXkSJKrJ1GTJA1nxYMjyTbgJmBLV3odcLSq9gHPTnL+BGqSpIFMYo/jx8CLgPlufg64uZs+AsxOoPYgSQ4mOZrk6IkTJ8ZuSJJ0xooHR1XNV9XJBaUtwL3d9DywfQK1xWM4VFWzVTU7M7PkjY+SpGUa4s7xU8Bm4CSwtZtf6dpE7Lr205P6qx/R8bc9a9XWLUkPZ4irqo4B+7vpPcDxCdQkSQMZYo/jJuAzSS4Fngh8idGhppWsSZIGMrE9jqqa6/68B7gc+ALwzKr68UrXJtWDJOlsgzwdt6r+gzNXQk2kJkkahneOS5KaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkppMPDiSbEvymSSHk7yvq92Y5EiS6xa8b9k1SdJwhtjjeBnwoaq6FDg/yR8DG6pqH7Ajye4kVy63NsD4JUkLbBxgHd8HfiXJzwK/AJwEbu6W3QbsBy4eo3b34hUmOQgcBNi5c+eKNiNJ690QexyfB3YDfwjcBTwKuLdbNg9sB7aMUTtLVR2qqtmqmp2ZmVnRZiRpvRsiON4C/H5VvYlRcLwY2Nwt29qN4dQYNUnSgIb4wfto4KIkG4CnA29jdIgJYA9wHDg2Rk2SNKAhznG8FfgA8Hjgi8C7gMNJdgBXAHuBGqMmSRrQxPc4qurLVfWkqtpaVZdX1TwwB9wBHKiqk+PUJj1+SdKDDbHHcZaqup8zV0eNXZMkDceTy5KkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWrSKziSvDDJpkkPRpK09vXd4/hV4PYk70/ym5MckCRpbesVHFX1pqraB3wE+GCSu5O8smVFSW5I8pxu+sYkR5Jct2D5smuSpOH0PVT1oiSfAN4IvB3YC7ym70qSXAo8tqo+meRKYEMXRDuS7B6n1tKsJGl8G3u+79eAP6qqb50uJHlVny9Mch7wV8BnkjwXmANu7hbfBuwHLh6jdvcS6zwIHATYuXNnn2FKknrqe47j7cBjAJK8OsmmqvpGz699OfAN4M+ApwGvBe7tls0D24EtY9TOUlWHqmq2qmZnZmZ6DlOS1Eff4PgY8KRuejvw4YZ1XAwcqqr7gA8BnwM2d8u2dmM4NUZNkjSgvj94t1XVTQBV9RbgwoZ1/DvwS930LLCL0SEmgD3AceDYGDVJ0oD6nuP4bpI/Ab7M6HDTfzWs40bgr5NcBZzH6BzH3yXZAVzB6ER7AYeXWZMkDajvHscrgf8Gng/8EHhZ3xVU1Q+q6gVVdVlVXVJV9zAKjzuAA1V1sqrml1vrOw5J0srou8dxAfA9RiekAa4CPrjclVbV/Zy5OmrsmiRpOH33OP4eeNyC+UxgLJKkKdB3j2O+qt4x0ZFIkqZC3+D4fJKPMjo89UOAqvrcxEYlSVqz+gbH/wF3MbqiCkZXNxkckrQO9QqOqro+yZMZnef4NvCdiY5KkrRm9X3I4XuA64G3MrqZ7yOTHJQkae3qe1XVRVX1fOCBqvo0o8tzJUnrUN/gOJHkjcC2JK8A7pvgmCRJa1jf4Hg5cBL4IqO9jVdOakCSpLWtb3C8ALgf+BLwQDcvSVqH+gZHutdm4ErgsomNSJK0pvW9HPemBbPvS3LDhMYjSVrjegVHkoV7GOdz5j91kiStM33vHD+wYPp/gWsmMBZJ0hToGxy3M3rMyGk/l+Qyn1clSetP3+B4M6PLcb8KPBXYBPwTPq9Kktad3g85rKpnnZ5J8o9V9aYJjUmStIb1DY6fJLkG+DpwEfCTyQ1JkrSW9b2P44WM7hi/CvhpvAFQktatvvdxfD/JJznzWPUfTXRUkqQ1y8eqS5Ka+Fh1SVITH6suSWqy3Meqv2piI5IkrWl9T47/D/DuCY9FkjQF+p4cv2XSA5EkTYe+h6ruTPLciY5EkjQV+t45/hvA65LcCfwQqKp6xuSGJUlaqx42OJJcU1U3VNWBh3ufJGn9eKRDVb93eiLJeyc8FknSFOh7jgPgiRMbhSRpajzSOY7HJnkxkAXTAFSVjx2RpHXokfY4PgbsBp6wYPr0fJMk25P8Szd9Y5IjSa5bsHzZNUnScB52j6Oqrl/Bdb0D2JzkSmBDVe1LckOS3Yz+j49l1arq7hUcoyTpEbSc41i2JM9gdBnvfcAccHO36DZg/5i1pdZ3MMnRJEdPnDixco1IkiYfHEk2AW8Eru1KW4B7u+l5YPuYtbNU1aGqmq2q2ZmZmZVrRpI0yB7HtcBfVNUD3fwpYHM3vbUbwzg1SdKAhvjB+0zgtUluB34deA5nDjHtAY4Dx8aoSZIG1PeRI8tWVZednu7C43eBw0l2AFcAe4EaoyZJGtCgh3qqaq6q5hmd5L4DOFBVJ8epDTl+SdIAexxLqar7OXN11Ng1SdJwPLksSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJajLx4EhyQZJbktya5ONJNiW5McmRJNcteN+ya5Kk4Qyxx/ES4J1VdTlwH3AVsKGq9gE7kuxOcuVyawOMX5K0wMZJr6CqblgwOwO8FPjzbv42YD9wMXDzMmt3L15nkoPAQYCdO3euTCOSJGDAcxxJLgG2Ad8B7u3K88B2YMsYtbNU1aGqmq2q2ZmZmRXuRJLWt0GCI8ljgPcAVwOngM3doq3dGMapSZIGNMTJ8U2MDi+9vqruAY4xOsQEsAc4PmZNkjSgiZ/jAF4NPBV4Q5I3AB8AXpZkB3AFsBco4PAya5KkAU18j6Oq/rKqtlXVXPe6CZgD7gAOVNXJqppfbm3S45ckPdgQexxnqar7OXN11Ng1SdJwPLksSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJajKVwZHkxiRHkly32mORpPVm6oIjyZXAhqraB+xIsnu1xyRJ68nG1R7AMswBN3fTtwH7gbsXviHJQeBgN3sqyTeXua4Lge8t82vHkrevxlqBVex5lay3fmH99Wy/y/P4h1owjcGxBbi3m54HnrD4DVV1CDg07oqSHK2q2XH/nmmy3npeb/3C+uvZflfe1B2qAk4Bm7vprUxnD5I0tabxh+4xRoenAPYAx1dvKJK0/kzjoapPAIeT7ACuAPZOcF1jH+6aQuut5/XWL6y/nu13haWqJr2OFZdkG3A58Lmqum+1xyNJ68lUBockafVM4zkOSdIqMjgewrl2d3qSjUm+neT27nVRkuuTfCXJexe8r1dtrUuyPcnhbvq8JJ/qPs+rx62tRYv6fVyS7y74rGe6+lnf031ra0mSC5LckuTWJB9Psmmc3qa03wdty937BtueDY4lnKN3pz8F+GhVzVXVHPAoRlenPQ34bpJnJpntU1ud4ffXnQO7idE9PwCvA452n+ezk5w/Zm1NWaLfpwNvPv1ZV9WJpb6n+9ZWo6dH8BLgnVV1OXAfcBXL7G1K+72WBdtyVd3Zd9tdqe3Z4FjaHGffnT7t9gLPS/L5JB8GngH8bY1Ocv0DcClwWc/aWvdj4EWMbhCFB3+eR4DZMWtrzeJ+9wLXJPliknd1tTnO/p7uW1tTquqGqrq1m50BXsrye1uqtqYs0e+PWLAtJ9lI/213RbZng2Npi+9O376KY1kpXwF+q6r2Aw8wuolycY9L9T11/xZVNV9VJxeU+vY1lf0v0e8twL6qugT45SRP4Rzq97QklwDbgO9wDn++py3o91YevC3/DgP3a3As7Vy8O/1rVfWf3fRdLN1j39q0GafXaez/SFX9oJu+C9jNOdZvkscA7wGuZh18vov6XbwtD/75rsl/pDXgXLw7/W+S7EmyAXgeo988Fve4VN/nwr9F377Olf4/m+Tnkzwa+G3gXzmH+k2yidHhpddX1T2c45/vEv0u3pa/ytD9VpWvRS/gZ7oP453AvwEXrPaYVqCnJwNfA+4E3szol4YvAO8Gvgn8Yt/aavfS0PPt3Z+PB77e9fAVYMM4tdXuq0e/Bxj9Jvo14A+62lnf031rq93XEn2+BrgfuL17vWK5vU1pv3+6cFvu3jPo9uwNgA8h6+Du9CSbgWcB/1xV32qpTZuMHlGzH/hsdecDxqlNo6W+p/vW1rpxepvGfpcy5PZscEiSmniOQ5LUxOCQJDUxOCRJTQwOSVITg0OS1OT/Ad73pzWCpGefAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(count    99527.000000\n",
       " mean       106.265958\n",
       " std        266.909012\n",
       " min          3.000000\n",
       " 25%         26.000000\n",
       " 50%         39.000000\n",
       " 75%        128.000000\n",
       " max      25184.000000\n",
       " Name: len1, dtype: float64,\n",
       " count     99527.000000\n",
       " mean       1003.299788\n",
       " std        1282.737142\n",
       " min           4.000000\n",
       " 25%         467.000000\n",
       " 50%         783.000000\n",
       " 75%        1204.000000\n",
       " max      183608.000000\n",
       " Name: len2, dtype: float64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.query('type==\\'sl\\'').len1.plot.hist()\n",
    "# train_df.query('type==\\'ss\\'').len2.plot.hist()\n",
    "plt.show()\n",
    "\n",
    "train_df.query('type==\\'sl\\'').len1.describe(),train_df.query('type==\\'sl\\'').len2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "hybrid-monthly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(count    98802.000000\n",
       " mean      1112.845681\n",
       " std       1222.216924\n",
       " min        100.000000\n",
       " 25%        559.000000\n",
       " 50%        851.000000\n",
       " 75%       1291.000000\n",
       " max      77827.000000\n",
       " Name: len1, dtype: float64,\n",
       " count    98802.000000\n",
       " mean      1111.824568\n",
       " std       1174.277097\n",
       " min        104.000000\n",
       " 25%        555.000000\n",
       " 50%        851.000000\n",
       " 75%       1287.000000\n",
       " max      46249.000000\n",
       " Name: len2, dtype: float64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.query('type==\\'ll\\'').len1.plot.hist()\n",
    "# train_df.query('type==\\'ss\\'').len2.plot.hist()\n",
    "plt.show()\n",
    "\n",
    "train_df.query('type==\\'ll\\'').len1.describe(),train_df.query('type==\\'ll\\'').len2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "spanish-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(CFG['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "occupied-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataframe, probs=None):\n",
    "        self.df = dataframe\n",
    "        self.probs = probs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text1 = str(self.df.source.values[idx])\n",
    "        text2 = str(self.df.target.values[idx])\n",
    "        \n",
    "        prob = self.probs[idx]\n",
    "        \n",
    "        label1 = self.df.labelA.values[idx]\n",
    "        label2 = self.df.labelB.values[idx]\n",
    "        \n",
    "        return text1, text2, label1, label2, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "derived-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    text = tokenizer([x[0] for x in data], text_pair=[x[1] for x in data], padding='max_length', truncation=True, max_length=CFG['max_len'], return_tensors='pt')\n",
    "    input_ids = text['input_ids']\n",
    "    attention_mask = text['attention_mask']\n",
    "    token_type_ids = text['token_type_ids']\n",
    "    label1 = torch.LongTensor([x[2] for x in data])\n",
    "    label2 = torch.LongTensor([x[3] for x in data])\n",
    "    prob = torch.Tensor([x[4] for x in data])\n",
    "    return input_ids, attention_mask, token_type_ids, label1, label2, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "brazilian-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, CFG):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(CFG['model'])\n",
    "        self.fc1 = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "        self.fc2 = nn.Linear(self.bert.config.hidden_size, 2)\n",
    " \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        text = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)[1]\n",
    "        y1 = self.fc1(text)\n",
    "        y2 = self.fc2(text)\n",
    "        return y1, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ready-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGM():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, epsilon=0.1, emb_name='word_embeddings'):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0:\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "\n",
    "    def restore(self, emb_name='word_embeddings'):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "            self.backup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "chemical-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "        \n",
    "def train_model(model, train_loader):\n",
    "    model.train() \n",
    "    fgm = FGM(model)\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    tk = tqdm(train_loader, total=len(train_loader), position=0, leave=True)\n",
    "    for step, batch in enumerate(tk):\n",
    "        input_ids, attention_mask, token_type_ids, y1, y2, prob = batch\n",
    "        \n",
    "        input_ids, attention_mask, token_type_ids = input_ids.to(device), attention_mask.to(device), token_type_ids.to(device)\n",
    "        y1, y2, prob = y1.to(device), y2.to(device), prob.to(device)\n",
    "        \n",
    "        with autocast():\n",
    "            output1, output2 = model(input_ids, attention_mask, token_type_ids)\n",
    "            loss = criterion(output1, y1) / 2 + criterion(output2, y2) / 2\n",
    "            \n",
    "            idx1 = y1>-1\n",
    "            if idx1.sum():\n",
    "                loss += nn.KLDivLoss()(F.log_softmax(output1[idx1], dim=1), prob[idx1])\n",
    "            idx2 = y2>-1\n",
    "            if idx2.sum():\n",
    "                loss += nn.KLDivLoss()(F.log_softmax(output2[idx2], dim=1), prob[idx2])\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # 对抗训练\n",
    "        fgm.attack() # 在embedding上添加对抗扰动\n",
    "        with autocast():\n",
    "            output1, output2 = model(input_ids, attention_mask, token_type_ids)\n",
    "            loss_adv = criterion(output1, y1) / 2 + criterion(output2, y2) / 2\n",
    "            \n",
    "            idx1 = y1>-1\n",
    "            if idx1.sum():\n",
    "                loss_adv += nn.KLDivLoss()(F.log_softmax(output1[idx1], dim=1), prob[idx1])\n",
    "            idx2 = y2>-1\n",
    "            if idx2.sum():\n",
    "                loss_adv += nn.KLDivLoss()(F.log_softmax(output2[idx2], dim=1), prob[idx2])\n",
    "        scaler.scale(loss_adv).backward() # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "        fgm.restore() # 恢复embedding参数\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad() \n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[-1]['lr']\n",
    "\n",
    "        losses.update(loss.item(), y1.size(0))\n",
    "        tk.set_postfix(loss=losses.avg, lr=lr)\n",
    "  \n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def test_model(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "\n",
    "    y_truth1, y_pred1 = [], []\n",
    "    y_truth2, y_pred2 = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tk = tqdm(val_loader, total=len(val_loader), position=0, leave=True)\n",
    "        for step, (input_ids, attention_mask, token_type_ids, y1, y2, prob) in enumerate(tk):\n",
    "            input_ids, attention_mask, token_type_ids = input_ids.to(device), attention_mask.to(device), token_type_ids.to(device)\n",
    "            y1, y2, prob = y1.to(device), y2.to(device), prob.to(device)\n",
    "        \n",
    "            output1, output2 = model(input_ids, attention_mask, token_type_ids)\n",
    "            \n",
    "            loss = criterion(output1, y1) / 2 + criterion(output2, y2) / 2\n",
    "        \n",
    "            losses.update(loss.item(), y1.size(0))\n",
    "            tk.set_postfix(loss=losses.avg)\n",
    "            \n",
    "            idx1 = y1>-1\n",
    "            if idx1.sum():\n",
    "                y_truth1.extend(y1[idx1].cpu().numpy())\n",
    "                y_pred1.extend(output1[idx1].softmax(1)[:,1].cpu().numpy())\n",
    "            idx2 = y2>-1\n",
    "            if idx2.sum():\n",
    "                y_truth2.extend(y2[idx2].cpu().numpy())\n",
    "                y_pred2.extend(output2[idx2].softmax(1)[:,1].cpu().numpy())\n",
    "  \n",
    "    def best_f1(y_truth, y_pred):   \n",
    "        thresholds = []\n",
    "        for thresh in np.arange(0.4, 0.61, 0.1):\n",
    "            thresh = np.round(thresh, 2)\n",
    "            res = f1_score(y_truth, (y_pred >= thresh).astype(int))\n",
    "            thresholds.append([thresh, res])\n",
    "        thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "        best_thresh = thresholds[0][0]\n",
    "        best_score = thresholds[0][1]\n",
    "        print(thresholds)\n",
    "        return best_score\n",
    "    \n",
    "    f1 = (best_f1(y_truth1, y_pred1) + best_f1(y_truth2, y_pred2)) / 2\n",
    "       \n",
    "    return losses.avg, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "portuguese-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(s):\n",
    "    with open('log.txt','a')as f:\n",
    "        f.write(str(s)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "neural-houston",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7080 [00:00<?, ?it/s]c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "100%|██████████| 7080/7080 [2:02:16<00:00,  1.04s/it, loss=0.392, lr=1.88e-5]  \n",
      "100%|██████████| 1770/1770 [13:06<00:00,  2.25it/s, loss=0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4, 0.821950321234194], [0.5, 0.8079269611873134], [0.6, 0.7849070360918702]]\n",
      "[[0.4, 0.6738376127689105], [0.5, 0.6367183782240411], [0.6, 0.5911975860992613]]\n",
      "0.7478939670015523\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7080 [00:00<?, ?it/s]c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "100%|██████████| 7080/7080 [2:00:36<00:00,  1.02s/it, loss=0.326, lr=1.4e-5]   \n",
      "100%|██████████| 1770/1770 [13:04<00:00,  2.25it/s, loss=0.168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4, 0.828501543766791], [0.5, 0.8208754208754209], [0.6, 0.8050059489710483]]\n",
      "[[0.4, 0.7016208812114756], [0.5, 0.6877873443116276], [0.6, 0.6553357481192532]]\n",
      "0.7650612124891333\n",
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7080 [00:00<?, ?it/s]c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "100%|██████████| 7080/7080 [2:00:33<00:00,  1.02s/it, loss=0.286, lr=7.55e-6]  \n",
      "100%|██████████| 1770/1770 [13:05<00:00,  2.25it/s, loss=0.166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4, 0.8305915156343359], [0.5, 0.8247775782131073], [0.6, 0.8097578097578096]]\n",
      "[[0.4, 0.7000964320154291], [0.5, 0.6759575773512139], [0.6, 0.6440516005733398]]\n",
      "0.7653439738248825\n",
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7080 [00:00<?, ?it/s]c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "100%|██████████| 7080/7080 [2:00:36<00:00,  1.02s/it, loss=0.255, lr=2.11e-6]  \n",
      "100%|██████████| 1770/1770 [13:03<00:00,  2.26it/s, loss=0.166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4, 0.8299972254151968], [0.5, 0.8265554683951942], [0.6, 0.8167692506348729]]\n",
      "[[0.4, 0.7026985469362651], [0.5, 0.6916088536504789], [0.6, 0.6694725530581178]]\n",
      "0.7663478861757309\n",
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7080 [00:00<?, ?it/s]c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "100%|██████████| 7080/7080 [2:00:36<00:00,  1.02s/it, loss=0.239, lr=0]        \n",
      "100%|██████████| 1770/1770 [13:07<00:00,  2.25it/s, loss=0.167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4, 0.8305206177360293], [0.5, 0.8245853497125367], [0.6, 0.8174586110513868]]\n",
      "[[0.4, 0.6994757843674205], [0.5, 0.6873215785054576], [0.6, 0.6638883855770973]]\n",
      "0.7649982010517249\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seed_everything(CFG['seed'])\n",
    "\n",
    "folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed'])\\\n",
    "                    .split(np.arange(train_df.shape[0]), train_df['stratify'].values)\n",
    "\n",
    "cv = [] \n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "    \n",
    "    print(fold)\n",
    "    \n",
    "    log(fold)\n",
    "    \n",
    "    if fold != 0:\n",
    "        continue\n",
    "\n",
    "    train = train_df.loc[trn_idx]\n",
    "    val = train_df.loc[val_idx]\n",
    "    \n",
    "    train_set = MyDataset(train, all_probs[trn_idx])\n",
    "    val_set = MyDataset(val, all_probs[val_idx])\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=CFG['train_bs'], collate_fn=collate_fn, shuffle=True, num_workers=CFG['num_workers'])\n",
    "    val_loader = DataLoader(val_set, batch_size=CFG['valid_bs'], collate_fn=collate_fn, shuffle=False, num_workers=CFG['num_workers'])\n",
    "    \n",
    "    steps_per_epoch = len(train_loader)\n",
    "    \n",
    "    best_f1 = 0\n",
    "    \n",
    "    model =  Model(CFG).to(device)\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    optimizer = AdamW(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, 0.05*CFG['epochs']*steps_per_epoch, CFG['epochs']*steps_per_epoch)\n",
    "\n",
    "    for epoch in range(CFG['epochs']):\n",
    "\n",
    "        print('epoch:',epoch)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        train_loss = train_model(model, train_loader)\n",
    "        val_loss, val_f1 = test_model(model, val_loader)\n",
    "        \n",
    "        print(val_f1)\n",
    "        log(val_f1)\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), '{}_fold_{}.pt'.format(CFG['model'].split('/')[-1], fold))\n",
    "            \n",
    "    cv.append(best_f1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "desirable-continent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7663478861757309]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ready-interval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8850 [00:00<?, ?it/s]c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "100%|██████████| 8850/8850 [3:33:51<00:00,  1.45s/it, loss=0.388, lr=1.88e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8850/8850 [2:34:41<00:00,  1.05s/it, loss=0.325, lr=1.4e-5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8850/8850 [2:36:16<00:00,  1.06s/it, loss=0.288, lr=7.55e-6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8850/8850 [2:36:57<00:00,  1.06s/it, loss=0.262, lr=2.11e-6]  \n"
     ]
    }
   ],
   "source": [
    "seed_everything(CFG['seed'])\n",
    "\n",
    "\n",
    "train_set = MyDataset(train_df, all_probs)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=CFG['train_bs'], collate_fn=collate_fn, shuffle=True, num_workers=CFG['num_workers'])\n",
    "\n",
    "steps_per_epoch = len(train_loader)\n",
    "\n",
    "model =  Model(CFG).to(device)\n",
    "\n",
    "scaler = GradScaler()\n",
    "optimizer = AdamW(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, 0.05*CFG['epochs']*steps_per_epoch, CFG['epochs']*steps_per_epoch)\n",
    "\n",
    "for epoch in range(4):\n",
    "\n",
    "    print('epoch:',epoch)\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    train_loss = train_model(model, train_loader)\n",
    "    \n",
    "    torch.save(model.state_dict(), '{}_full_epoch_{}.pt'.format(CFG['model'].split('/')[-1], epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "miniature-cedar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8850/8850 [2:46:47<00:00,  1.13s/it, loss=0.394, lr=1.88e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8850/8850 [2:42:56<00:00,  1.10s/it, loss=0.326, lr=1.4e-5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8850/8850 [2:42:46<00:00,  1.10s/it, loss=0.283, lr=7.55e-6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8850/8850 [2:43:10<00:00,  1.11s/it, loss=0.248, lr=2.11e-6]  \n"
     ]
    }
   ],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "    'model': 'hfl/chinese-macbert-base',\n",
    "#     'model': 'nghuyong/ernie-1.0',\n",
    "    'max_len': 512, \n",
    "    'epochs': 5,\n",
    "    'train_bs': 30, \n",
    "    'valid_bs': 30,\n",
    "    'lr': 2e-5, \n",
    "    'num_workers': 0,\n",
    "    'accum_iter': 1, \n",
    "    'weight_decay': 1e-6, \n",
    "    'device': 0,\n",
    "}\n",
    "tokenizer = BertTokenizer.from_pretrained(CFG['model'])\n",
    "\n",
    "seed_everything(CFG['seed'])\n",
    "\n",
    "\n",
    "train_set = MyDataset(train_df, all_probs)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=CFG['train_bs'], collate_fn=collate_fn, shuffle=True, num_workers=CFG['num_workers'])\n",
    "\n",
    "steps_per_epoch = len(train_loader)\n",
    "\n",
    "model =  Model(CFG).to(device)\n",
    "\n",
    "scaler = GradScaler()\n",
    "optimizer = AdamW(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, 0.05*CFG['epochs']*steps_per_epoch, CFG['epochs']*steps_per_epoch)\n",
    "\n",
    "for epoch in range(4):\n",
    "\n",
    "    print('epoch:',epoch)\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    train_loss = train_model(model, train_loader)\n",
    "    \n",
    "    torch.save(model.state_dict(), '{}_full_epoch_{}.pt'.format(CFG['model'].split('/')[-1], epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-advice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33187 [00:00<?, ?it/s]c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "  3%|▎         | 915/33187 [13:21<8:07:18,  1.10it/s, loss=0.864, lr=1.1e-6] "
     ]
    }
   ],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "    'model': 'hfl/chinese-macbert-large',\n",
    "#     'model': 'nghuyong/ernie-1.0',\n",
    "    'max_len': 512, \n",
    "    'epochs': 5,\n",
    "    'train_bs': 8, \n",
    "    'valid_bs': 8,\n",
    "    'lr': 1e-5, \n",
    "    'num_workers': 0,\n",
    "    'accum_iter': 1, \n",
    "    'weight_decay': 1e-6, \n",
    "    'device': 0,\n",
    "}\n",
    "tokenizer = BertTokenizer.from_pretrained(CFG['model'])\n",
    "\n",
    "seed_everything(CFG['seed'])\n",
    "\n",
    "\n",
    "train_set = MyDataset(train_df, all_probs)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=CFG['train_bs'], collate_fn=collate_fn, shuffle=True, num_workers=CFG['num_workers'])\n",
    "\n",
    "steps_per_epoch = len(train_loader)\n",
    "\n",
    "model =  Model(CFG).to(device)\n",
    "\n",
    "scaler = GradScaler()\n",
    "optimizer = AdamW(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, 0.05*CFG['epochs']*steps_per_epoch, CFG['epochs']*steps_per_epoch)\n",
    "\n",
    "for epoch in range(4):\n",
    "\n",
    "    print('epoch:',epoch)\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    train_loss = train_model(model, train_loader)\n",
    "    \n",
    "    torch.save(model.state_dict(), '{}_full_epoch_{}.pt'.format(CFG['model'].split('/')[-1], epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-suspect",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
