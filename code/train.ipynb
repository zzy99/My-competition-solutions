{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ordered-qatar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "multiple-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "    'model': 'hfl/chinese-macbert-base',\n",
    "    'max_len': 512, \n",
    "    'epochs': 4,\n",
    "    'train_bs': 16, \n",
    "    'valid_bs': 16,\n",
    "    'lr': 1e-5, \n",
    "    'num_workers': 4,\n",
    "    'accum_iter': 1, \n",
    "    'weight_decay': 1e-6, \n",
    "    'device': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "personal-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['seed'])\n",
    "\n",
    "torch.cuda.set_device(CFG['device'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "close-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =  pd.read_csv('train.csv')\n",
    "test_df =  pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "grand-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "enhanced-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['stratify'] = 3*(train_df.labelA+1)+train_df.labelB+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "strategic-japanese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>labelA</th>\n",
       "      <th>labelB</th>\n",
       "      <th>type</th>\n",
       "      <th>len1</th>\n",
       "      <th>len2</th>\n",
       "      <th>stratify</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>谁能打破科比81分纪录？奥尼尔给出5个候选人，补充利拉德比尔！</td>\n",
       "      <td>NBA现役能入名人堂的球星很多，但是能被立铜像只有2人</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>请扩散！明天，黄金埠这些地方会停电！</td>\n",
       "      <td>生活｜这几个地方注意啦！1月12日有部分线路停电检修</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>居家健身增强免疫！（三）</td>\n",
       "      <td>原来是背影杀手#你愿意和我做朋友吗#户外健身</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>太极拳罗师傅被洋人打伤，叶问霸气复仇？</td>\n",
       "      <td>非常完美：感动！女嘉宾告白赵杰被拒绝，尹康霸气上台挽留！</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>恭喜哈登！篮网因祸得福，29+7超巨大概率复出，3换4交易方案出炉</td>\n",
       "      <td>三英缺席杜兰特，篮网迎战湖人NBA重头大戏！</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ss</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69573</th>\n",
       "      <td>凯尔特人是苏超的霸主，不过随着格拉斯哥流浪者本赛季的强势回归，球队本赛季遭遇了前所未有的挑战...</td>\n",
       "      <td>019，利物浦vs曼特斯特联  利物浦上赛季遥遥领先的拿到了冠军，本以为利物浦是准备做百分...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ll</td>\n",
       "      <td>341</td>\n",
       "      <td>1517</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69574</th>\n",
       "      <td>谁是中国影史最另类的导演？ 答案只有一个：姜文。  能够切中时代脉搏，真正做到商业与艺术的完...</td>\n",
       "      <td>最近，有眼尖的网友发现，在电视剧版《天官赐福》豆瓣页面，导演一栏竟然是姜文。  虽然这大概率...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ll</td>\n",
       "      <td>3635</td>\n",
       "      <td>2210</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69575</th>\n",
       "      <td>“建设海南自由贸易港，打造我国面向太平洋、印度洋的重要开放门户，是国家重大战略。”近日，中国...</td>\n",
       "      <td>法国：禽类及其相关产品暂停输华 近日，法国官方通报该国家禽发生H5N8亚型高致病性禽流感疫情...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ll</td>\n",
       "      <td>1658</td>\n",
       "      <td>1806</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69576</th>\n",
       "      <td>[辉瑞和Moderna现在承诺，到7月底前将在美国分别生产3亿剂疫苗，并在欧洲和其他地区生产...</td>\n",
       "      <td>国际在线报道（记者高俊雅）：南非总统拉马福萨2月28号宣布，随着该国每日新增病例的持续下降以...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ll</td>\n",
       "      <td>1658</td>\n",
       "      <td>759</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69577</th>\n",
       "      <td>【作者：楠鱼说娱乐】 说起吴孟达，作为港片里的黄金配角，很多电影都有他的身影，当然了大家印象...</td>\n",
       "      <td>近日，各媒体都在关注和报道吴孟达病情状况，虽然本人或家人都没有回应，但好友田启文却时不时透露...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ll</td>\n",
       "      <td>783</td>\n",
       "      <td>907</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69578 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  source  \\\n",
       "0                        谁能打破科比81分纪录？奥尼尔给出5个候选人，补充利拉德比尔！   \n",
       "1                                     请扩散！明天，黄金埠这些地方会停电！   \n",
       "2                                           居家健身增强免疫！（三）   \n",
       "3                                    太极拳罗师傅被洋人打伤，叶问霸气复仇？   \n",
       "4                      恭喜哈登！篮网因祸得福，29+7超巨大概率复出，3换4交易方案出炉   \n",
       "...                                                  ...   \n",
       "69573  凯尔特人是苏超的霸主，不过随着格拉斯哥流浪者本赛季的强势回归，球队本赛季遭遇了前所未有的挑战...   \n",
       "69574  谁是中国影史最另类的导演？ 答案只有一个：姜文。  能够切中时代脉搏，真正做到商业与艺术的完...   \n",
       "69575  “建设海南自由贸易港，打造我国面向太平洋、印度洋的重要开放门户，是国家重大战略。”近日，中国...   \n",
       "69576  [辉瑞和Moderna现在承诺，到7月底前将在美国分别生产3亿剂疫苗，并在欧洲和其他地区生产...   \n",
       "69577  【作者：楠鱼说娱乐】 说起吴孟达，作为港片里的黄金配角，很多电影都有他的身影，当然了大家印象...   \n",
       "\n",
       "                                                  target  labelA  labelB type  \\\n",
       "0                            NBA现役能入名人堂的球星很多，但是能被立铜像只有2人     0.0    -1.0   ss   \n",
       "1                             生活｜这几个地方注意啦！1月12日有部分线路停电检修     0.0    -1.0   ss   \n",
       "2                                 原来是背影杀手#你愿意和我做朋友吗#户外健身     0.0    -1.0   ss   \n",
       "3                           非常完美：感动！女嘉宾告白赵杰被拒绝，尹康霸气上台挽留！     0.0    -1.0   ss   \n",
       "4                                 三英缺席杜兰特，篮网迎战湖人NBA重头大戏！     1.0    -1.0   ss   \n",
       "...                                                  ...     ...     ...  ...   \n",
       "69573   019，利物浦vs曼特斯特联  利物浦上赛季遥遥领先的拿到了冠军，本以为利物浦是准备做百分...    -1.0     0.0   ll   \n",
       "69574  最近，有眼尖的网友发现，在电视剧版《天官赐福》豆瓣页面，导演一栏竟然是姜文。  虽然这大概率...    -1.0     1.0   ll   \n",
       "69575  法国：禽类及其相关产品暂停输华 近日，法国官方通报该国家禽发生H5N8亚型高致病性禽流感疫情...    -1.0     0.0   ll   \n",
       "69576  国际在线报道（记者高俊雅）：南非总统拉马福萨2月28号宣布，随着该国每日新增病例的持续下降以...    -1.0     0.0   ll   \n",
       "69577  近日，各媒体都在关注和报道吴孟达病情状况，虽然本人或家人都没有回应，但好友田启文却时不时透露...    -1.0     0.0   ll   \n",
       "\n",
       "       len1  len2  stratify  \n",
       "0        31    27       3.0  \n",
       "1        18    26       3.0  \n",
       "2        12    22       3.0  \n",
       "3        19    30       3.0  \n",
       "4        33    22       6.0  \n",
       "...     ...   ...       ...  \n",
       "69573   341  1517       1.0  \n",
       "69574  3635  2210       2.0  \n",
       "69575  1658  1806       1.0  \n",
       "69576  1658   759       1.0  \n",
       "69577   783   907       1.0  \n",
       "\n",
       "[69578 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "outdoor-laundry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9c324426f34c0985e05fdffda6fbaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=109540.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6218e420461d4bd4932afdd1d215c61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41af1f543d2d4dca80e875564ec8ae10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7783c213480044968b85fcd80c61ff39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d638f58766a4d259e5ce7f8468321a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=268961.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(CFG['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "loose-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text1 = str(self.df.source.values[idx])\n",
    "        text2 = str(self.df.target.values[idx])\n",
    "        \n",
    "        label1 = self.df.labelA.values[idx]\n",
    "        label2 = self.df.labelB.values[idx]\n",
    "        \n",
    "        return text1, text2, label1, label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "compatible-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    text = tokenizer([x[0] for x in data], text_pair=[x[1] for x in data], padding='max_length', truncation=True, max_length=CFG['max_len'], return_tensors='pt')\n",
    "    input_ids = text['input_ids']\n",
    "    attention_mask = text['attention_mask']\n",
    "    token_type_ids = text['token_type_ids']\n",
    "    label1 = torch.LongTensor([x[2] for x in data])\n",
    "    label2 = torch.LongTensor([x[3] for x in data])\n",
    "    return input_ids, attention_mask, token_type_ids, label1, label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "inside-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, CFG):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(CFG['model'])\n",
    "        self.fc1 = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "        self.fc2 = nn.Linear(self.bert.config.hidden_size, 2)\n",
    " \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        text = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)[1]\n",
    "        y1 = self.fc1(text)\n",
    "        y2 = self.fc2(text)\n",
    "        return y1, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "proved-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "        \n",
    "def train_model(model, train_loader):\n",
    "    model.train() \n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    tk = tqdm(train_loader, total=len(train_loader), position=0, leave=True)\n",
    "    for step, batch in enumerate(tk):\n",
    "        input_ids, attention_mask, token_type_ids, y1, y2 = batch\n",
    "        \n",
    "        input_ids, attention_mask, token_type_ids = input_ids.to(device), attention_mask.to(device), token_type_ids.to(device)\n",
    "        y1, y2 = y1.to(device), y2.to(device)\n",
    "        \n",
    "        with autocast():\n",
    "            output1, output2 = model(input_ids, attention_mask, token_type_ids)\n",
    "            loss = criterion(output1, y1) / 2 + criterion(output2, y2) / 2\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad() \n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[-1]['lr']\n",
    "\n",
    "        losses.update(loss.item(), y1.size(0))\n",
    "        tk.set_postfix(loss=losses.avg, lr=lr)\n",
    "  \n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def test_model(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "\n",
    "    y_truth1, y_pred1 = [], []\n",
    "    y_truth2, y_pred2 = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tk = tqdm(val_loader, total=len(val_loader), position=0, leave=True)\n",
    "        for step, (input_ids, attention_mask, token_type_ids, y1, y2) in enumerate(tk):\n",
    "            input_ids, attention_mask, token_type_ids = input_ids.to(device), attention_mask.to(device), token_type_ids.to(device)\n",
    "            y1, y2 = y1.to(device), y2.to(device)\n",
    "        \n",
    "            output1, output2 = model(input_ids, attention_mask, token_type_ids)\n",
    "            \n",
    "            loss = criterion(output1, y1) / 2 + criterion(output2, y2) / 2\n",
    "        \n",
    "            losses.update(loss.item(), y1.size(0))\n",
    "            tk.set_postfix(loss=losses.avg)\n",
    "            \n",
    "            idx1 = y1>-1\n",
    "            if idx1.sum():\n",
    "                y_truth1.extend(y1[idx1].cpu().numpy())\n",
    "                y_pred1.extend(output1[idx1].softmax(1)[:,1].cpu().numpy())\n",
    "            idx2 = y2>-1\n",
    "            if idx2.sum():\n",
    "                y_truth2.extend(y2[idx2].cpu().numpy())\n",
    "                y_pred2.extend(output2[idx2].softmax(1)[:,1].cpu().numpy())\n",
    "  \n",
    "    def best_f1(y_truth, y_pred):   \n",
    "        thresholds = []\n",
    "        for thresh in np.arange(0.4, 0.61, 0.1):\n",
    "            thresh = np.round(thresh, 2)\n",
    "            res = f1_score(y_truth, (y_pred >= thresh).astype(int))\n",
    "            thresholds.append([thresh, res])\n",
    "        thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "        best_thresh = thresholds[0][0]\n",
    "        best_score = thresholds[0][1]\n",
    "        print(thresholds)\n",
    "        return best_score\n",
    "    \n",
    "    f1 = (best_f1(y_truth1, y_pred1) + best_f1(y_truth2, y_pred2)) / 2\n",
    "       \n",
    "    return losses.avg, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-outdoors",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cbebefeed440489790c1d76281a0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1306488754.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3479/3479 [44:18<00:00,  1.31it/s, loss=0.336, lr=8.95e-6]\n",
      "100%|██████████| 870/870 [08:29<00:00,  1.71it/s, loss=0.153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4, 0.7954806587514363], [0.5, 0.782537405205985], [0.6, 0.7581896551724138]]\n",
      "[[0.4, 0.6612779060816013], [0.5, 0.6562631800927878], [0.6, 0.6356517733763243]]\n",
      "0.7283792824165187\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3479/3479 [44:18<00:00,  1.31it/s, loss=0.257, lr=5.41e-6]\n",
      "100%|██████████| 870/870 [08:29<00:00,  1.71it/s, loss=0.155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4, 0.7929444778512728], [0.5, 0.779746835443038], [0.6, 0.7588028169014086]]\n",
      "[[0.4, 0.6367384333486028], [0.5, 0.6001003512293026], [0.6, 0.5572519083969466]]\n",
      "0.7148414555999378\n",
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3479/3479 [44:15<00:00,  1.31it/s, loss=0.164, lr=1.61e-6]\n",
      "100%|██████████| 870/870 [08:29<00:00,  1.71it/s, loss=0.195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4, 0.7857142857142856], [0.5, 0.7842053307008885], [0.6, 0.7812563118561906]]\n",
      "[[0.4, 0.6471782379212342], [0.5, 0.6388415672913118], [0.6, 0.630963096309631]]\n",
      "0.7164462618177598\n",
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 2437/3479 [31:02<13:12,  1.31it/s, loss=0.093, lr=1.53e-7] "
     ]
    }
   ],
   "source": [
    "seed_everything(CFG['seed'])\n",
    "\n",
    "folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed'])\\\n",
    "                    .split(np.arange(train_df.shape[0]), train_df['stratify'].values)\n",
    "\n",
    "cv = [] \n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "    \n",
    "    print(fold)\n",
    "\n",
    "    train = train_df.loc[trn_idx]\n",
    "    val = train_df.loc[val_idx]\n",
    "    \n",
    "    train_set = MyDataset(train)\n",
    "    val_set = MyDataset(val)\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=CFG['train_bs'], collate_fn=collate_fn, shuffle=True, num_workers=CFG['num_workers'])\n",
    "    val_loader = DataLoader(val_set, batch_size=CFG['valid_bs'], collate_fn=collate_fn, shuffle=False, num_workers=CFG['num_workers'])\n",
    "    \n",
    "    steps_per_epoch = len(train_loader)\n",
    "    \n",
    "    best_f1 = 0\n",
    "    \n",
    "    model =  Model(CFG).to(device)\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    optimizer = AdamW(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, 0.05*CFG['epochs']*steps_per_epoch, CFG['epochs']*steps_per_epoch)\n",
    "\n",
    "    for epoch in range(CFG['epochs']):\n",
    "\n",
    "        print('epoch:',epoch)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        train_loss = train_model(model, train_loader)\n",
    "        val_loss, val_f1 = test_model(model, val_loader)\n",
    "        \n",
    "        print(val_f1)\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), '{}_fold_{}.pt'.format(CFG['model'].split('/')[-1], fold))\n",
    "            \n",
    "    cv.append(best_f1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-living",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
